{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c55608",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d2ec812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2ada5d",
   "metadata": {},
   "source": [
    "## small dataset\n",
    "\n",
    "sales numbers can't be negative this is called data errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8dd433ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales_numbers = [21, 22, -108, 31, -1, 32, 34, 31]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7867c448",
   "metadata": {},
   "source": [
    "## Converting in tensorflow object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "34b26f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a220f",
   "metadata": {},
   "source": [
    "## Printing tensorflow object in data form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cfeefc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# for sales in tf_dataset:\n",
    "#     print(sales.numpy())\n",
    "    \n",
    "# iterate tfdataset directly using .numpy() function or .as_numpy_iterator()\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f122510",
   "metadata": {},
   "source": [
    "## take function --> prints only first n element\n",
    "\n",
    "see only first n elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "123db794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "for sales in tf_dataset.take(n):\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddf5fb9",
   "metadata": {},
   "source": [
    "## filter function --> using filter function we can filter out the data, here we are filtering negative data\n",
    "\n",
    "using filter function we can filter out the negative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e98a70c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "31\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.filter(lambda x: x > 0)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbe4ce8",
   "metadata": {},
   "source": [
    "## map function\n",
    "\n",
    "suppose this data is in us dollars and we want to convert this in indan rupees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9dca6398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512\n",
      "1584\n",
      "2232\n",
      "2304\n",
      "2448\n",
      "2232\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.map(lambda y: y*72)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098fc802",
   "metadata": {},
   "source": [
    "## shuffle function\n",
    "\n",
    "to shuffle the element or dataset\n",
    "\n",
    "https://stackoverflow.com/questions/53514495/what-does-batch-repeat-and-shuffle-do-with-tensorflow-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6e833c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512\n",
      "2304\n",
      "2232\n",
      "2448\n",
      "1584\n",
      "2232\n"
     ]
    }
   ],
   "source": [
    "buffer = 3\n",
    "tf_dataset = tf_dataset.shuffle(buffer)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7b80b",
   "metadata": {},
   "source": [
    "## batch function\n",
    "\n",
    "create the batch of the dataset, batching the traing samples and distributing them on multi GPU environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ee8eea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1584 2304 1512]\n",
      "[2232 2448 2232]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "for sales_batch in tf_dataset.batch(batch_size):\n",
    "    print(sales_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ebeb7c",
   "metadata": {},
   "source": [
    "## All above function in single line\n",
    "\n",
    "whatever we have done in above steps we can do all that thing in single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "85753e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1512 2232 2304]\n",
      "[2448 2232 1584]\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "buffer = 3\n",
    "batch_size = 3\n",
    "tf_dataset = tf_dataset.filter(lambda x: x > 0).map(lambda y: y*72).shuffle(buffer).batch(batch_size)\n",
    "for sales_batch in tf_dataset:\n",
    "    print(sales_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefbfd9b",
   "metadata": {},
   "source": [
    "# Tensorflow input pipline is reading the data from a datasource than doing filtering, mapping, shuffling and creating batches (all kind of transformations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb16dea",
   "metadata": {},
   "source": [
    "## loading the dataset in tensorflow object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "92ef16dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images/cat/20 Reasons Why Cats Make the Best Pets....jpg'\n",
      "b'images/cat/7 Foods Your Cat Can_t Eat.jpg'\n",
      "b'images/cat/A cat appears to have caught the....jpg'\n",
      "b'images/cat/Adopt-A-Cat Month\\xc2\\xae - American Humane....jpg'\n",
      "b'images/cat/All About Your Cat_s Tongue.jpg'\n"
     ]
    }
   ],
   "source": [
    "images_ds = tf.data.Dataset.list_files('images/*/*', shuffle = False)\n",
    "for files in images_ds.take(5):\n",
    "    print(files.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653be154",
   "metadata": {},
   "source": [
    "## shuffling the dataset with buffer size of 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "dc5fbc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images/dog/Aggression in dogs _ Animal Humane Society.jpg'\n",
      "b'images/cat/Cat Throwing Up_ Normal or Cause for....jpg'\n",
      "b'images/dog/The 25 Cutest Dog Breeds - Most....jpg'\n",
      "b'images/dog/Colitis in Dogs _ VCA Animal Hospital.jpg'\n",
      "b'images/dog/25 Best Small Dog Breeds \\xe2\\x80\\x94 Cute and....jpg'\n"
     ]
    }
   ],
   "source": [
    "images_ds = images_ds.shuffle(200)\n",
    "\n",
    "for file in images_ds.take(5):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e321b57",
   "metadata": {},
   "source": [
    "## creating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "51eb4e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = ['cat', 'dog']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4c6559",
   "metadata": {},
   "source": [
    "## counting total images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "091e7bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(images_ds)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28f8eeb",
   "metadata": {},
   "source": [
    "## spliting the data into testing(20%) and training(80%) samples  \n",
    "\n",
    ".take = It will take the image accoring to the input size\n",
    "\n",
    ".skip = skip is the opposite of take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1761e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = int(image_count * 0.8)\n",
    "\n",
    "train_ds = images_ds.take(training_size)\n",
    "test_ds = images_ds.skip(training_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c3277e",
   "metadata": {},
   "source": [
    "## varifying the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f3f7da8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds))\n",
    "print(len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f81651",
   "metadata": {},
   "source": [
    "## finding the image label from there folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "cf9b381b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'images/cat/Giving cats food with an antibody may....jpg'\n",
    "\n",
    "# spliting_name = s.split('/')\n",
    "# spliting_name = spliting_name[-2]\n",
    "# spliting_name\n",
    "\n",
    "# or directly \n",
    "s.split('/')[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ca6a5",
   "metadata": {},
   "source": [
    "## creating the function using tensorflow method which will give the label name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a6bfc54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    return tf.strings.split(file_path, os.path.sep)[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c1366b",
   "metadata": {},
   "source": [
    "## creating the function which will process the image like decoding it and changing the image dimension in 128*128 px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "33d000e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize(img, [128,128])\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5a6c1a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:  tf.Tensor(\n",
      "[[[6.54062500e+01 8.14062500e+01 1.07406250e+02]\n",
      "  [6.86093750e+01 8.46093750e+01 1.10609375e+02]\n",
      "  [7.17968750e+01 8.77968750e+01 1.13796875e+02]\n",
      "  ...\n",
      "  [5.06093750e+01 7.06093750e+01 9.56093750e+01]\n",
      "  [4.90317383e+01 6.90317383e+01 9.40317383e+01]\n",
      "  [4.65053711e+01 6.65053711e+01 9.15053711e+01]]\n",
      "\n",
      " [[6.64379883e+01 8.34379883e+01 1.09437988e+02]\n",
      "  [6.56093750e+01 8.26093750e+01 1.08609375e+02]\n",
      "  [6.44062500e+01 8.14062500e+01 1.07406250e+02]\n",
      "  ...\n",
      "  [5.60864258e+01 7.60864258e+01 1.01086426e+02]\n",
      "  [5.16093750e+01 7.16093750e+01 9.66093750e+01]\n",
      "  [6.22968750e+01 7.92968750e+01 1.05296875e+02]]\n",
      "\n",
      " [[6.12812500e+01 8.32812500e+01 1.07281250e+02]\n",
      "  [6.30131836e+01 8.50131836e+01 1.09013184e+02]\n",
      "  [6.11782227e+01 8.31782227e+01 1.07178223e+02]\n",
      "  ...\n",
      "  [5.16093750e+01 7.16093750e+01 9.66093750e+01]\n",
      "  [5.66562500e+01 7.66562500e+01 1.01656250e+02]\n",
      "  [7.42856445e+01 8.82856445e+01 1.15285645e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.28564453e+00 1.28564453e+00 1.28564453e+00]\n",
      "  [1.16943359e+00 1.16943359e+00 1.16943359e+00]\n",
      "  [5.60302734e+00 3.41552734e+00 8.12500000e-01]\n",
      "  ...\n",
      "  [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "  [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "  [2.81250000e-01 2.81250000e-01 2.81250000e-01]]\n",
      "\n",
      " [[3.39111328e+00 3.39111328e+00 3.39111328e+00]\n",
      "  [1.87646484e+00 1.87646484e+00 1.87646484e+00]\n",
      "  [5.08642578e+00 3.79687500e+00 1.20312500e+00]\n",
      "  ...\n",
      "  [1.95556641e+00 1.95556641e+00 1.95556641e+00]\n",
      "  [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "  [2.81250000e-01 2.81250000e-01 2.81250000e-01]]\n",
      "\n",
      " [[2.81250000e-01 2.81250000e-01 2.81250000e-01]\n",
      "  [2.03125000e-01 2.03125000e-01 2.03125000e-01]\n",
      "  [3.23730469e-01 3.23730469e-01 8.25195312e-02]\n",
      "  ...\n",
      "  [1.45996094e+00 1.45996094e+00 1.45996094e+00]\n",
      "  [3.00000000e+00 3.00000000e+00 3.00000000e+00]\n",
      "  [2.05712891e+00 2.05712891e+00 2.05712891e+00]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label:  tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "Image:  tf.Tensor(\n",
      "[[[  0.7470703 100.913086   66.913086 ]\n",
      "  [  6.8408203 105.84082    76.84082  ]\n",
      "  [  3.7490234 104.08496    74.41699  ]\n",
      "  ...\n",
      "  [  6.908203   97.74219    66.825195 ]\n",
      "  [  3.7470703  88.831055   59.831055 ]\n",
      "  [  0.5830078  78.08008    47.08008  ]]\n",
      "\n",
      " [[  1.7480469 100.48535    71.984375 ]\n",
      "  [  1.5029297 104.25293    75.25293  ]\n",
      "  [  2.256836  107.256836   77.256836 ]\n",
      "  ...\n",
      "  [  0.5175781  93.02539    67.024414 ]\n",
      "  [  0.75       95.25195    63.250977 ]\n",
      "  [  2.5078125  93.50781    62.507812 ]]\n",
      "\n",
      " [[  5.3398438 108.33984    79.33984  ]\n",
      "  [  2.3398438 109.33984    79.33984  ]\n",
      "  [  0.        108.25488    79.25488  ]\n",
      "  ...\n",
      "  [  0.        104.58496    74.58496  ]\n",
      "  [  9.155273  110.15527    78.15527  ]\n",
      "  [  6.0097656 103.774414   70.51953  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 24.91504    26.254883   18.225586 ]\n",
      "  [ 15.725586   18.725586    9.725586 ]\n",
      "  [  7.3251953  10.325195    1.3251953]\n",
      "  ...\n",
      "  [116.15039   124.16992    89.83008  ]\n",
      "  [105.50488   118.174805   88.174805 ]\n",
      "  [104.225586  122.740234   86.91504  ]]\n",
      "\n",
      " [[ 14.762695   16.762695    5.7626953]\n",
      "  [ 12.996094   15.996094    6.9960938]\n",
      "  [ 11.753906   13.753906    2.7539062]\n",
      "  ...\n",
      "  [121.99512   123.006836   91.00293  ]\n",
      "  [116.25      122.25391    88.25391  ]\n",
      "  [108.76074   120.76074    84.76074  ]]\n",
      "\n",
      " [[ 10.915039   12.915039    1.9150391]\n",
      "  [ 14.583008   16.583008    5.583008 ]\n",
      "  [ 25.095703   35.594727   21.761719 ]\n",
      "  ...\n",
      "  [114.74707   120.74707    84.74707  ]\n",
      "  [115.33203   121.33203    87.33203  ]\n",
      "  [110.41992   117.41992    83.41992  ]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label:  tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "Image:  tf.Tensor(\n",
      "[[[126.5  108.5   98.5 ]\n",
      "  [130.25 112.25 102.25]\n",
      "  [136.25 120.75 111.25]\n",
      "  ...\n",
      "  [171.75 129.75 104.75]\n",
      "  [173.5  133.5  108.5 ]\n",
      "  [176.5  136.5  111.5 ]]\n",
      "\n",
      " [[128.   110.   100.  ]\n",
      "  [139.   121.   111.  ]\n",
      "  [117.5  102.    92.5 ]\n",
      "  ...\n",
      "  [177.25 138.25 114.25]\n",
      "  [177.   140.   117.5 ]\n",
      "  [180.   143.   120.5 ]]\n",
      "\n",
      " [[144.5  126.5  116.5 ]\n",
      "  [139.75 121.75 111.75]\n",
      "  [118.75 103.25  93.75]\n",
      "  ...\n",
      "  [178.   142.5  121.5 ]\n",
      "  [177.5  143.5  124.  ]\n",
      "  [181.   147.   127.5 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[143.5  137.75 134.5 ]\n",
      "  [159.5  151.75 147.5 ]\n",
      "  [185.   182.75 180.25]\n",
      "  ...\n",
      "  [220.75 220.75 215.75]\n",
      "  [230.5  235.   234.25]\n",
      "  [231.5  234.   235.5 ]]\n",
      "\n",
      " [[143.5  133.5  127.75]\n",
      "  [156.25 146.75 143.25]\n",
      "  [192.5  191.25 188.25]\n",
      "  ...\n",
      "  [216.75 213.25 205.25]\n",
      "  [223.75 225.75 218.25]\n",
      "  [229.25 232.25 231.25]]\n",
      "\n",
      " [[152.5  135.5  128.75]\n",
      "  [176.75 172.75 167.25]\n",
      "  [172.   164.   163.5 ]\n",
      "  ...\n",
      "  [209.75 200.   187.75]\n",
      "  [214.75 211.25 197.75]\n",
      "  [220.   220.75 214.5 ]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label:  tf.Tensor(b'cat', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(process_image)\n",
    "for img, label in train_ds.take(3):\n",
    "    print(\"Image: \", img)\n",
    "    print(\"Label: \", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8a644c",
   "metadata": {},
   "source": [
    "## scaling the image inbetween 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5e742fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    return image/255, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7b4ab",
   "metadata": {},
   "source": [
    "## checking all above operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ab4f0654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Image:  [0.03999694 0.07136948 0.01254596 1.        ]\n",
      "*****Label:  b'dog'\n",
      "*****Image:  [0.44313726 0.28627452 0.04705882]\n",
      "*****Label:  b'dog'\n",
      "*****Image:  [0.10364583 0.23477328 0.09779412]\n",
      "*****Label:  b'cat'\n",
      "*****Image:  [0.99607843 0.99607843 0.99607843]\n",
      "*****Label:  b'dog'\n",
      "*****Image:  [0.49607843 0.4254902  0.38627452]\n",
      "*****Label:  b'cat'\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(scale)\n",
    "for image, label in train_ds.take(5):\n",
    "    print(\"*****Image: \", image.numpy()[0][0])\n",
    "    print(\"*****Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f5e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
